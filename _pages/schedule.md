---
layout: page
permalink: /schedule/
title: Schedule
description: 
nav: true
nav_order: 4
---


All seminars are happening on Thursday 4-5pm (CET), unless the description specifies a different day/time.

---------

**March 28th - [Xingyou (Richard) Song](https://xingyousong.github.io/) (Google)** 


Title: OmniPred: Towards Universal Regressors with Language Models 

Abstract: 

Over the broad landscape of experimental design, regression has been a powerful tool to accurately predict the outcome metrics of a system or model given a set of parameters, but has been traditionally restricted to methods which are only applicable to a specific task. In this paper, we introduce OmniPred, a framework for training language models as universal end-to-end regressors over (x, y) evaluation data from diverse real world experiments. Using data sourced from Google Vizier, one of the largest blackbox optimization databases in the world, our extensive experiments demonstrate that through only textual representations of mathematical parameters and values, language models are capable of very precise numerical regression, and if given the opportunity to train over multiple tasks at scale, can significantly outperform traditional regression models.



---------

**April 4th - [Sebastian Pineda](https://relea.informatik.uni-freiburg.de/people/sebastian-pineda)** 


Title: Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How

Abstract: 

With the ever-increasing number of pretrained models, machine learning practitioners are continuously faced with the decision of which pretrained model to use, and how to finetune it for a new dataset. In this paper, we propose a methodology that jointly searches for the optimal pretrained model and the hyperparameters for finetuning it. Our method transfers knowledge about the performance of many pretrained models with multiple hyperparameter configurations on a series of datasets. To this aim, we evaluated over 20k hyperparameter configurations for finetuning 24 pretrained image classification models on 87 datasets to generate a large-scale meta-dataset. We metalearn a gray-box performance predictor on the learning curves of this meta-dataset and use it for fast hyperparameter optimization on new datasets. We empirically demonstrate that our resulting approach can quickly select an accurate pretrained model for a new dataset together with its optimal hyperparameters.



---------

**April 18th - [Julien Siems](https://scholar.google.de/citations?user=rKgTTh8AAAAJ&hl=de) and [Riccardo Grazzi](https://scholar.google.de/citations?user=9Tlyx1IAAAAJ&hl=de)** 


Title: 

Abstract: 

---------



